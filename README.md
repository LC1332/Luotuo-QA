# 驼铃QA : 仅使用6B语言模型的阅读理解系统

孙骜, 李鲁鲁

这是一个简短的repo，完成之后会被合并到CamelBell完整的项目中

## 引言

本文是对于我们驼铃QA模型，一个基于GLM-6B的中文阅读理解模型，的简短技术汇报。在语言模型的垂类应用中，关于一段特定文本的理解和QA是一个很重要的问题，有以下原因: 1. 大量涉密企业、或者是金融企业并不能够把自己的机密文档输入到公开的API中。2. 训练或者tuning一个语言模型的成本仍然很高，对于很多专业领域，如果能够在回答问题之前给定一段特定上下文的文本，可以使得模型有快速适应特定垂直领域的能力。3. 给定的文本的事实可以被用户控制，而不像语言模型的输出完全依赖模型的记忆和概率模型，可以让模型在对话中给出更符合事实的回答。

所以在驼铃的这个实验中，我们试图让一个6B的模型，通过Low Rank Adaptation的微调，争取实现对一段特定长度（大约200-600字）的阅读理解的能力。这对于我们之后完成更大的文本的搜索-QA系统，是一个重要的初步尝试。

注意到，完成一个中文的阅读理解模型是Non-trivial的。1、没数据。2、更泛化的提问能力。 3、使用一个更简洁的架构。

基于这一点， 数据， 模型

主要贡献

1.开源模型
2.增广数据的方法，开源数据
3.验证out of world 可行性


